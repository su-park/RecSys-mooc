{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pd.read_csv(\"./ratings.csv\", names = ['uid','iid','rating','timestamp'], header=1)\n",
    "#tab = tab.sample(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1263</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid   iid  rating   timestamp\n",
       "0    1  1029     3.0  1260759179\n",
       "1    1  1061     3.0  1260759182\n",
       "2    1  1129     2.0  1260759185\n",
       "3    1  1172     4.0  1260759205\n",
       "4    1  1263     2.0  1260759151"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100003 entries, 0 to 100002\n",
      "Data columns (total 4 columns):\n",
      "uid          100003 non-null int64\n",
      "iid          100003 non-null int64\n",
      "rating       100003 non-null float64\n",
      "timestamp    100003 non-null int64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "tab.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of User:  671\n",
      "# of Item:  9066\n"
     ]
    }
   ],
   "source": [
    "print(\"# of User: \", data.df['uid'].nunique())\n",
    "print(\"# of Item: \", data.df['iid'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid = np.random.choice(tab['iid'].unique(),2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = tab[tab['iid'].isin(iid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(line_format='user item rating', rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(tab[['uid', 'iid', 'rating']], reader)\n",
    "train, test = train_test_split(data, test_size=.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7ffa3e4ee390>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gph = SVD(random_state=10)\n",
    "gph.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gph.test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import accuracy\n",
    "from collections import defaultdict\n",
    "\n",
    "class Metrics:\n",
    "    def MAE(pred):\n",
    "        return accuracy.mae(pred, verbose=False)\n",
    "    \n",
    "    def RMSE(pred):\n",
    "        return accuracy.rmse(pred, verbose=False)\n",
    "    \n",
    "    def TopN(pred, n=10, minRating=4.0):\n",
    "        '''Return the top-N recommendation for each user from a set of predictions.\n",
    "        Args:\n",
    "            predictions(list of Prediction objects): The list of predictions, as\n",
    "                returned by the test method of an algorithm.\n",
    "            n(int): The number of recommendation to output for each user. Default\n",
    "                is 10.\n",
    "\n",
    "        Returns:\n",
    "        A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "            [(raw item id, rating estimation), ...] of size n.\n",
    "        '''\n",
    "        topN = defaultdict(list)\n",
    "        \n",
    "        # First map the predictions to each user.\n",
    "        for uid, iid, obsRating, prdRating, _ in pred:\n",
    "            if (obsRating >= minRating):\n",
    "                topN[uid].append((iid, prdRating))\n",
    "                \n",
    "        # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "        for uid, ratings in topN.items():\n",
    "            ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "            topN[uid] = ratings[:n]\n",
    "            \n",
    "        return topN\n",
    "        \n",
    "    def Hitrate(prdTopN, prdLeftOut):\n",
    "        hits = 0\n",
    "        total = 0\n",
    "        \n",
    "        for leftout in prdLeftOut:\n",
    "            user_leftout = leftout[0]\n",
    "            item_leftout = leftout[1]\n",
    "            \n",
    "            hit = False\n",
    "            for item_TopN, Rating_TopN in prdTopN[int(user_leftout)]:\n",
    "                if(int(item_TopN) == int(item_leftout)):\n",
    "                    hit = True\n",
    "                    break\n",
    "            if (hit):\n",
    "                hits += 1\n",
    "            total += 1\n",
    "            \n",
    "        return hits/total\n",
    "    \n",
    "    def CumeHitrate(prdTopN, prdLeftOut, cutRating=0):\n",
    "        hits = 0\n",
    "        total = 0\n",
    "        \n",
    "        for leftout in prdLeftOut:\n",
    "            user_leftout = leftout[0]\n",
    "            item_leftout = leftout[1]\n",
    "            obsRating = leftout[2]\n",
    "            \n",
    "            if (obsRating >= cutRating):\n",
    "                hit = False\n",
    "                for item_TopN, Rating_TopN in prdTopN[int(user_leftout)]:\n",
    "                    if(int(item_TopN) == int(item_leftout)):\n",
    "                        hit = True\n",
    "                        break\n",
    "                if (hit):\n",
    "                    hits += 1\n",
    "                total += 1\n",
    "       \n",
    "        return hits/total                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.7135\n",
      "RMSE:  0.9228\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE: \", round(Metrics.MAE(pred),4))\n",
    "print(\"RMSE: \", round(Metrics.RMSE(pred),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOCV = LeaveOneOut(n_splits=1, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SANITY CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of User:  671\n",
      "# of Item:  1810\n",
      "# of Every Combinations:  671 * 1810 = 1214510\n",
      "# of Represented Instances: 20652\n",
      "# of Left-out Testset: 671\n",
      "# of Left-out Trainset: 19981\n",
      "# of Every Combination Except Trainset: 1177684\n"
     ]
    }
   ],
   "source": [
    "print(\"# of User: \", data.df['uid'].nunique())\n",
    "print(\"# of Item: \", data.df['iid'].nunique())\n",
    "print(\"# of Every Combinations: \", data.df['uid'].nunique(), \"*\", data.df['iid'].nunique(),\"=\", data.df['uid'].nunique()*data.df['iid'].nunique())\n",
    "print(\"# of Represented Instances:\", data.df.shape[0])\n",
    "#print(\"# of Represented Instances:\", data.df.loc[:,['uid','iid']].apply(lambda df: str(df['uid'])+\":\"+str(df['iid']), axis=1).nunique())\n",
    "for train, test in LOOCV.split(data):\n",
    "    train_leftout, test_leftout = train, test    \n",
    "    gph.fit(train_leftout)\n",
    "    test0 = train_leftout.build_anti_testset()\n",
    "    break\n",
    "print(\"# of Left-out Testset:\", pd.DataFrame(test_leftout).shape[0])\n",
    "cnt = 0\n",
    "for i in list(train_leftout.ur.values()):\n",
    "    cnt += len(i)\n",
    "print(\"# of Left-out Trainset:\", cnt)\n",
    "print(\"# of Every Combination Except Trainset:\", pd.DataFrame(test0).shape[0])\n",
    "#print(\"# of Every Combination Except Trainset:\", pd.DataFrame(test0,columns=['uid','iid','rating']).loc[:,['uid','iid']].apply(lambda df: str(df['uid'])+\":\"+str(df['iid']), axis=1).nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECK BUILD_ANTI_TESTSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = pd.DataFrame({'uid':[\"u{}\".format(i) for i in range(100)]})\n",
    "iid = pd.DataFrame({'iid':[\"i{}\".format(i) for i in range(10)]})\n",
    "\n",
    "uid['key'] = 0\n",
    "iid['key'] = 0\n",
    "tab = uid.merge(iid, how='outer').drop(\"key\", axis=1)\n",
    "tab['rating'] = np.random.randint(1, 6, tab.shape[0])\n",
    "\n",
    "reader = Reader(line_format='user item rating', rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(tab[['uid', 'iid', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# of User: \", data.df['uid'].nunique())\n",
    "print(\"# of Item: \", data.df['iid'].nunique())\n",
    "print(\"# of Every Combinations: \", data.df['uid'].nunique(), \"*\", data.df['iid'].nunique(),\"=\", data.df['uid'].nunique()*data.df['iid'].nunique())\n",
    "print(\"# of Represented Instances:\", data.df.shape[0])\n",
    "#print(\"# of Represented Instances:\", data.df.loc[:,['uid','iid']].apply(lambda df: str(df['uid'])+\":\"+str(df['iid']), axis=1).nunique())\n",
    "for train, test in LOOCV.split(data):\n",
    "    train_leftout, test_leftout = train, test    \n",
    "    gph.fit(train_leftout)\n",
    "    test0 = train_leftout.build_anti_testset()\n",
    "    break\n",
    "print(\"# of Left-out Testset:\", pd.DataFrame(test_leftout).shape[0])\n",
    "cnt = 0\n",
    "for i in list(train_leftout.ur.values()):\n",
    "    cnt += len(i)\n",
    "print(\"# of Left-out Trainset:\", cnt)\n",
    "print(\"# of Every Combination Except Trainset:\", pd.DataFrame(test0).shape[0])\n",
    "#print(\"# of Every Combination Except Trainset:\", pd.DataFrame(test0,columns=['uid','iid','rating']).loc[:,['uid','iid']].apply(lambda df: str(df['uid'])+\":\"+str(df['iid']), axis=1).nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for train, test in LOOCV.split(data):\n",
    "    gph.fit(train)\n",
    "    \n",
    "    prdLeftOut = gph.test(test)\n",
    "    \n",
    "    testset = train.build_anti_testset()\n",
    "    prdTestSet = gph.test(testset)\n",
    "    \n",
    "    prdTopN = Metrics.TopN(prdTestSet, n=10)\n",
    "    print(Metrics.Hitrate(prdTopN, prdLeftOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prdTopN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
